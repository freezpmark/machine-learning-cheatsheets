{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')  # this is not needed for langchain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden so bright, a carrot grew,\n",
      "With a smile so wide, and a vibrant hue.\n",
      "It danced in the breeze, so full of glee,\n",
      "A happy carrot, as happy as can be!\n",
      "\n",
      "With roots in the earth, it reached for the sky,\n",
      "Its leafy greens waving, saying \"hi!\"\n",
      "It shared its joy with all who passed by,\n",
      "A happy carrot, bringing smiles to the eye!\n",
      "\n",
      "So let us remember, in life's daily grind,\n",
      "To be like the carrot, with happiness entwined.\n",
      "Spread joy and laughter, wherever we go,\n",
      "Just like the happy carrot, all in a row!\n",
      "{'prompt_tokens': 37, 'completion_tokens': 128, 'total_tokens': 165}\n"
     ]
    }
   ],
   "source": [
    "# prompting\n",
    "def get_completion_and_token_count(\n",
    "    messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500\n",
    "):\n",
    "    # messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message[\"content\"]\n",
    "\n",
    "    token_dict = {\n",
    "        \"prompt_tokens\": response[\"usage\"][\"prompt_tokens\"],\n",
    "        \"completion_tokens\": response[\"usage\"][\"completion_tokens\"],\n",
    "        \"total_tokens\": response[\"usage\"][\"total_tokens\"],\n",
    "    }\n",
    "\n",
    "    return content, token_dict\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an assistant who responds in the style of Dr Seuss.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"write me a 4 sentence long poem about a happy carrot\"\"\",\n",
    "    },\n",
    "]\n",
    "response, token_dict = get_completion_and_token_count(messages)\n",
    "\n",
    "print(response)\n",
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"flagged\": false,\n",
      "  \"categories\": {\n",
      "    \"sexual\": false,\n",
      "    \"hate\": false,\n",
      "    \"harassment\": false,\n",
      "    \"self-harm\": false,\n",
      "    \"sexual/minors\": false,\n",
      "    \"hate/threatening\": false,\n",
      "    \"violence/graphic\": false,\n",
      "    \"self-harm/intent\": false,\n",
      "    \"self-harm/instructions\": false,\n",
      "    \"harassment/threatening\": false,\n",
      "    \"violence\": false\n",
      "  },\n",
      "  \"category_scores\": {\n",
      "    \"sexual\": 8.910085e-06,\n",
      "    \"hate\": 0.00013615482,\n",
      "    \"harassment\": 0.0023860661,\n",
      "    \"self-harm\": 7.5545418e-06,\n",
      "    \"sexual/minors\": 2.20487e-07,\n",
      "    \"hate/threatening\": 7.746158e-06,\n",
      "    \"violence/graphic\": 0.00012008196,\n",
      "    \"self-harm/intent\": 5.9765495e-07,\n",
      "    \"self-harm/instructions\": 3.4945369e-09,\n",
      "    \"harassment/threatening\": 0.0015225811,\n",
      "    \"violence\": 0.34292138\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# moderation\n",
    "response = openai.Moderation.create(\n",
    "    input=\"\"\"\n",
    "Here's the plan.  We get the warhead, \n",
    "and we hold the world ransom...\n",
    "...FOR ONE MILLION DOLLARS!\n",
    "\"\"\"\n",
    ")\n",
    "moderation_output = response[\"results\"][0]\n",
    "print(moderation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompting with LangChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.0)\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "customer_messages = prompt_template.format_messages(\n",
    "    style=customer_style, text=customer_email\n",
    ")\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_template.messages[0].prompt, end=\"\\n__2__\\n\")\n",
    "print(prompt_template.messages[0].prompt.input_variables, end=\"\\n__3__\\n\")\n",
    "print(type(customer_messages), end=\"\\n__4__\\n\")\n",
    "print(type(customer_messages[0]), end=\"\\n__5__\\n\")\n",
    "print(customer_messages[0], end=\"\\n__6__\\n\")\n",
    "print(customer_messages[0].content, end=\"\\n__7__\\n\")\n",
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
